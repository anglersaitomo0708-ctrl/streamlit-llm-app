#æ¡ä»¶ã®æ•´ç†
#ç”»é¢ã«å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ï¼‘ã¤ç”¨æ„
#å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰é€ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’LangChainã‚’ä½¿ã£ã¦LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦
#æ¸¡ã—ã€ãã®å›ç­”ãŒç”»é¢ã«è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
#ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§LLMã«æŒ¯èˆã‚ã›ã‚‹å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ
#Aã‚’é¸æŠï¼šé‡‘èã®å°‚é–€å®¶ã¨ã—ã¦æŒ¯èˆã†
#Bã‚’é¸æŠï¼šå¥åº·ç®¡ç†ã®å°‚é–€å®¶ã¨ã—ã¦æŒ¯èˆã†
#LLMã«é¸æŠå€¤ã«å¿œã˜ã¦LLMã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¤‰ãˆã‚‹
#ã€Œå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€ã¨ã€Œãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã®é¸æŠå€¤ã€ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚Š
#LLMã‹ã‚‰ã®å›ç­”ã‚’æˆ»ã‚Šå€¤ã¨ã—ã¦è¿”ã™é–¢æ•°ã‚’å®šç¾©ã—ã¦åˆ©ç”¨ã™ã‚‹
#WEBã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨æ“ä½œæ–¹æ³•ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ˜ç¤ºã™ã‚‹ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹
#Streamlit Community Cloudã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã
#ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ãã®Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã€Œ3.11ã€ã‚’é¸æŠã™ã‚‹

from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

#llmå‘¼ã³å‡ºã—é–¢æ•°
def get_llm_response(user_input: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’åŸºã«LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    """
    if expert_type == "é‡‘èã®å°‚é–€å®¶":
        system_prompt = "ã‚ãªãŸã¯é‡‘èã®å°‚é–€å®¶ã§ã™ã€‚å°‚é–€çš„ãªçŸ¥è­˜ã«åŸºã¥ãã€ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    elif expert_type == "å¥åº·ã®å°‚é–€å®¶":
        system_prompt = "ã‚ãªãŸã¯å¥åº·ã®å°‚é–€å®¶ã§ã™ã€‚æ „é¤Šã€é‹å‹•ã€ç”Ÿæ´»ç¿’æ…£ãªã©ã®è¦³ç‚¹ã‹ã‚‰é©åˆ‡ã«åŠ©è¨€ã—ã¦ãã ã•ã„ã€‚"
    else:
        system_prompt = "ã‚ãªãŸã¯è³ªå•è€…ã«ä¸å¯§ã«å¿œå¯¾ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

    chat = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]
    # ä¿®æ­£: generate ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
    response = chat.generate(messages)
    return response.content

#st.set_page_config(page_title="å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ’¬")

st.title("ğŸ’¬ å°‚é–€å®¶AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ **LangChain + Streamlit** ã‚’åˆ©ç”¨ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã§ã™ã€‚  
ä¸‹è¨˜ã®æ‰‹é †ã§æ“ä½œã§ãã¾ã™ğŸ‘‡
1. ã€Œå°‚é–€å®¶ã®ç¨®é¡ã€ã‚’é¸æŠ  
2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€é¸ã‚“ã å°‚é–€å®¶ã¨ã—ã¦AIãŒå›ç­”ã—ã¾ã™ã€‚
""")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ
expert_type = st.radio(
    "AIã®å°‚é–€å®¶ã¨ã—ã¦ã®å½¹å‰²ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    ("é‡‘èã®å°‚é–€å®¶", "å¥åº·ã®å°‚é–€å®¶")
)

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_area("è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=150)

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input.strip():
        with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
            answer = get_llm_response(user_input, expert_type)
        st.success("å›ç­”ï¼š")
        st.write(answer)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

st.caption("â€» ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒ‡ãƒ¢ç”¨ã§ã™ã€‚å®Ÿéš›ã®å°‚é–€çš„åˆ¤æ–­ã‚’ä»£æ›¿ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
